%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LaTeX Example: Project Report
%
% Source: http://www.howtotex.com
%
% Feel free to distribute this example, but please keep the referral
% to howtotex.com
% Date: March 2011 
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% How to use writeLaTeX: 
%
% You edit the source code here on the left, and the preview on the
% right shows you the result within a few seconds.
%
% Bookmark this page and share the URL with your co-authors. They can
% edit at the same time!
%
% You can upload figures, bibliographies, custom classes and
% styles using the files menu.
%
% If you're new to LaTeX, the wikibook is a great place to start:
% http://en.wikibooks.org/wiki/LaTeX
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Edit the title below to update the display in My Documents
%\title{Project Report}
%
%%% Preamble
\documentclass[paper=a4, fontsize=11pt]{scrartcl}
\usepackage[T1]{fontenc}
\usepackage{fourier}

\usepackage[english]{babel}															% English language/hyphenation
\usepackage[protrusion=true,expansion=true]{microtype}	
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage[pdftex]{graphicx}
\usepackage{grffile}  % Better extensions recognition (e.g. .png)
\usepackage{url}

% For page-wide images
\usepackage{chngpage}
\usepackage{calc}

\usepackage{mathtools}


%%% Custom sectioning
\usepackage{sectsty}
\allsectionsfont{\centering \normalfont\scshape}


%%% Custom headers/footers (fancyhdr package)
\usepackage{fancyhdr}
\pagestyle{fancyplain}
\fancyhead{}											% No page header
\fancyfoot[L]{}											% Empty 
\fancyfoot[C]{}											% Empty
\fancyfoot[R]{\thepage}									% Pagenumbering
\renewcommand{\headrulewidth}{0pt}			% Remove header underlines
\renewcommand{\footrulewidth}{0pt}				% Remove footer underlines
\setlength{\headheight}{13.6pt}


%%% Equation and float numbering
\numberwithin{equation}{section}		% Equationnumbering: section.eq#
\numberwithin{figure}{section}			% Figurenumbering: section.fig#
\numberwithin{table}{section}				% Tablenumbering: section.tab#


%%% Maketitle metadata
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} 	% Horizontal rule

\title{
		%\vspace{-1in} 	
		\usefont{OT1}{bch}{b}{n}
		\normalfont \normalsize \textsc{Simulation Project} \\ [25pt]
		\horrule{0.5pt} \\[0.4cm]
		\huge Project n$^{\text{o}}$2\\
		\horrule{2pt} \\[0.5cm]
}
\author{
		\normalfont 								\normalsize
        Claudio Peroni\\[-3pt]		\normalsize
        %\today
}
\date{}


%%% Begin document
\begin{document}
\maketitle
\section{Brief overview of the System and Model semplifications}
The system taken into account is a Flexible Cell of an automated factory (\textit{FMS}).
Raw parts are loaded on \textit{AGV}s and are then processed by up to 3 machines before being unloaded. The \textit{AGV}s sometimes need recharging, but apart from that are considered to become instantly available for loading a new piece and to move instantly from one machine to the next.
To build our model, we consider 6 stations, only half of which operates on the raw parts loaded on the \textit{AGV}s (\textit{M1}, \textit{M2}, \textit{M3}), while the remaining stations represent the loading, unloading and recharging of the \textit{AGV}s.

The \textit{Load} and \textit{Unload} stations are considered to be infinite servers stations (delay stations). The number of \textit{AGV}s represents the maximum number of clients in the system. Every other station in the model is supposed to be a \textit{SSSQ}. \textit{M1} is a complex station which follows a Round-Robin approach for the service of its clients. Once a client completes its work there, it is serviced by \textit{M2}, after which it might be sent back to \textit{M1} (passing by \textit{M3}) or directly to the \textit{Unload} station.

\section{Implementation and statistics}
\subsection{Code structure}
The simulator is made up of different modules. The core of the simulation is the \textit{engine()} function, which handles the next event in the \textit{FEL} for each iteration. The event can be an \textit{ARRIVAL}, a \textit{DEPARTURE} or a \textit{SELF\_TRANSITION}.

Each event is charachterised by station and time. Arriving clients can be queued or served depending on the state of the server(s) and, of course, the type of station - Delay Stations don't have a queue. Departing clients are routed to the next station based on assumed routing probabilities. The self transition is a particular type of departure that ignores routing and instead removes from service the current client, sending it back in queue; this is useful for the implementation of the Round-Robin policy of \textit{M1}.

Each station is charachterised by its type (\textit{Delay} or \textit{Server}), a routing table, and the probabilistic distribution that decides the service time for each job.

Since the aim of the simulation is to compute statistics, we use the regenerative method to draw them from a single simulation run. The way to do this is to define regeneration points, charachterised by the number of clients at each station and a triggering event. To simplify, we initialize the system already in this way.
The initialisation is chosen following 2 criteria:
\begin{itemize}
	\item \textit{M1} should be either empty or full since unfortunately it does not have the nice properties of stations charachterized by a negative exponential distribution;
	\item the clients should be distributed in such a way that the regeneration point is likely to happen often but at the same time not too common.
\end{itemize}
Our choice is to set \textit{M1} as empty and to distribute clients between the other stations based on the frequency of visits for each station in a test run.

Each regeneration cycle is forced to have minimum length to avoid very short cycles due to quick compensating events. Other than that the number of regeneration cycles has a minimum of 30 and depends also on the requested precision for the confidence value. By default, the requested precision for the intervals is 90\% with $\pm$5\% accuracy.

For every random choice in the project (\textit{e.g.} routing for each station, service time for each station\dots) a different stream from the \textit{rngs} library is used. The default seed is set to 123456789.

\subsection{Results}
The requested statistics are the mean \textbf{cycle time}, which is the time taken to an \textit{AGV} to come back to the beginning and start again, and the mean \textbf{manufacturing time}, which is basically the time an \textit{AGV} spends in the manufacturing stations (\textit{M1}, \textit{M2}, \textit{M3}).
\begin{align}
\text{\textit{Average Cycle Time}} &= 1203.727909 \\
\text{\textit{Cycle Time Confidence Interval}} &= [1202.431251, 1205.024567] \\
\text{\textit{Average Manufacturing Time}} &= 1043.373882 \\
\text{\textit{Manufacturing Time Confidence Interval}} &= [1041.878510, 1044.869254]
\end{align}

%%% TODO: RESULTS WITH M1

\section{Validation}
To verify that the results we got from our simulator are meaningful, we need to check wether simulations are coherent with the system taken into account. Since we do not have the chance to test a real system, we may check how our statistics compare to theoretical results computed for a simplified version of the system. The simplified version does in fact swap \textit{M1} with a negative exponential distributed \textit{SSSQ} station with short service time and a high probability of routing exiting jobs to itself again.
The new model becomes a Product Form Queueing Network, and as such we can apply the convolution methods and the MVA\_LI\&D Algorithm to it.

\subsection{Analysis} \label{subsec:analysis}
First, we can use the consistency laws
\begin{align}
V = VQ \label{eq:consistency_laws}
\end{align}
where $V$ is the visit count vector and $Q$ the routing probability matrix to get the value of $V$, since $Q$ is known. We then apply the Gauss Method to (\ref{eq:consistency_laws}), choosing $V_0 = 1$ (Load station as reference station) to get a single solution instead of infinite.
Then,
\begin{align}
V = \begin{bmatrix}1.0 & 12.5 & 1.25 & 0.25 & 1.0 & 0.4\end{bmatrix}
\end{align}
Recalling also that the mean service times $S_i$ are:
\begin{align}
S = \begin{bmatrix}60 & 10 & 80 & 100 & 50 & 90\end{bmatrix}
\end{align}
we can compute the value of $S_i V_i$ for each station, and the station whose value is the greatest is the bottleneck of the system. In this case the bottleneck turns out to be \textit{M1}\footnote{Notice that \textit{M2} comes second with $D_2 = 100$, so it might become the hidden bottleneck of the system. \label{ftn:hidden_bottleneck}}, so:
\begin{align}
V_b S_b = V_1 S_1 = 125 \label{eq:VbSb}
\end{align}
Letting the number of \textit{AVG}s in the system go to infinity, the throughput of the system (with reference station the Load station 0) $X_0$ tends to the reciprocal of $V_b S_b$:
\begin{align}
X_0(N) \xrightarrow{N\to\infty} \frac{1}{V_b S_b} = 0.008
\end{align}
Now we can effectively apply the MVA\_LI\&D Algorithm to compute the values of $X_i$, $U_i$, $\bar{w}_i$, $\bar{n}_i$ for $0 \le N \le 30$.

\includegraphics[width=\textwidth]{"img/X0"}

We can then compute the response time of the system with just one customer, which is $R(1) = V_1 S_1 + V_2 S_2 + V_3 S_3 = 250$ and use it to derive
\begin{align}
N^* = \frac{R(1) + Z}{V_b S_b} = 3.168
\end{align}
which represents the number of customers (\textit{AVG}s in this case) over which we expect to see queues in the system.

Using the same algorithm we can also compute the theoretical value of the average cycle and manufacturing times and  for $N = 10$.
\begin{align}
\text{\textit{Average Cycle Time}} &= 1297.17365 \\
\text{\textit{Average Manufacturing Time}} &= 1137.68264
\end{align}

\subsection{Validation}
Knowing the theoretical values, we can now launch our simulation and expect the results to be consistent with those. But each simulation run is a (pseudo)random process, so how do we check consistency? The simplest way is to run the experiment a number of times, checking wether the confidence intervals contains the true value around 90\% of the times, since we chose the confidence intervals with 90\%confidence. For instance, in the first run we do, the confidence interval computed with 90\% probability is $\left[1296.195280, 1298.195589\right]$, and it does contain the theoretical value.

Now, in figure \ref{fig:cycle_validation} we run the simulation 1000 times, checking that around 900 times the interval contains the theoretical values and that the intervals are almost symmetrical (checking for instance that some are higher and some lower in a comparable manner).
\begin{figure}
	\begin{adjustwidth}{-\oddsidemargin-0.5in}{-\rightmargin}
     		\centering
		\includegraphics[height = 0.82\paperheight]{"img/cycle_validation"}
		\caption{A night's worth of simulation. 1000 confidence intervals for the Cycle Time.}
		\label{fig:cycle_validation}
		\end{adjustwidth}
\end{figure}
The intervals including the theoretical value are 866, the intervals out of range are 134. We also notice that the intervals are almost symmetric with around half, 444, stay below and 422 stay above. The same goes for the "wrong" intervals, 61 of which stay completely over and 73 are completely under.
The numbers are absolutely similar for the manufacturing time confidence interval, and we could show a similar graph.

\section{Variations}
The following variations all concern the most complex station of the network, namely \textit{M1}.

\subsection{Original Project}
\texttt{Mean cycle time: 1203.727909\\
Cycle time semi-interval: 1.296658\\
CONFIDENCE INTERVAL for CYCLE TIME: [1202.431251, 1205.024567]\\
Mean manufacturing time: 1043.373882\\
Manufacturing time semi-interval: 1.495372\\
CONFIDENCE INTERVAL for MANUFACTURING TIME: [1041.878510, 1044.869254]}

These are the outputs of the simulator for the original project.

\subsection{Negative exponential instead of Hyper-Exponential with same mean} \label{subsec:proj2}
\texttt{Mean cycle time: 1202.599304\\
Cycle time semi-interval: 0.713844\\
CONFIDENCE INTERVAL for CYCLE TIME: [1201.885460, 1203.313148]\\
Mean manufacturing time: 1041.905798\\
Manufacturing time semi-interval: 0.947266\\
CONFIDENCE INTERVAL for MANUFACTURING TIME: [1040.958531, 1042.853064]}\\

This variant shows the effects of switching to a station M1 with a simpler distribution with same mean. While the numerical value of the mean for both cycle and manufacturing time does not change much, the variance is reduced and as a result the width of the interval is reduced (thus the precision increased)\footnote{Note that this is due to the fact that we imposed at least 30 regeneration cycles to compute the statistics, and that the number of cycles necessary for the requested performance is lower than 30. Otherwise we would have had the same width of the interval but with less cycles.}.

\subsection{Hyper-Exponential with tool consumption time of 10.000"} \label{subsec:proj3}
\texttt{Mean cycle time: 1265.498084\\
Cycle time semi-interval: 1.016637\\
CONFIDENCE INTERVAL for CYCLE TIME: [1264.481447, 1266.514721]\\
Mean manufacturing time: 1104.315544\\
Manufacturing time semi-interval: 0.975608\\
CONFIDENCE INTERVAL for MANUFACTURING TIME: [1103.339936, 1105.291152]}\\

This other variant is quite interesting actually. It shows that by increasing the tool consumption time we have an increase in the average cycle time. This is probably due to the variance of the Hyper-Exponential and to the paradox of the instantly-moving \textit{AVG}s. If we don't have idle times during the swapping of the piece, the Round-Robin policy is actually beneficial to the average cycle time, since it prevents very long jobs (which happen from time to time, more frequently for the Hyper-Exponential, which has an higher variance) from obstructing the server.

\subsection{Negative exponential (with same mean) and tool consumption time of 10.000"}
\texttt{Mean cycle time: 1203.155691\\
Cycle time semi-interval: 0.663368\\
CONFIDENCE INTERVAL for CYCLE TIME: [1202.492323, 1203.819059]\\
Mean manufacturing time: 1042.330756\\
Manufacturing time semi-interval: 0.645855\\
CONFIDENCE INTERVAL for MANUFACTURING TIME: [1041.684901, 1042.976612]}\\

The last variant shows that in the case of negative exponential distribution with same mean, the impact of a much higher consumption time is very different. In fact, the average cycle and manufacturing times stay almost the same, while the precision (inverse of the width of the confidence interval) further increases with respect to section \ref{subsec:proj2}.

\subsection{One more variation}
\texttt{Mean cycle time: 1202.356747\\
Cycle time semi-interval: 1.937429\\
CONFIDENCE INTERVAL for CYCLE TIME: [1200.419318, 1204.294176]\\
Mean manufacturing time: 1041.584513\\
Manufacturing time semi-interval: 2.289834\\
CONFIDENCE INTERVAL for MANUFACTURING TIME: [1039.294679, 1043.874346]}\\

After having analysed the baffling third project, we may want to investigate further the opposite extreme: what happens with a very small tool consumption time? The results above are obtained by keeping the Hyper-Exponential distribution and decreasing the value of the tool consumption time to 1s. As we might expect at this point, the mean cycle time does not change from the case with 10s, and this is undoubtedly due to the modelling assumption of the instantly moving \textit{AVG}s, and the considerations in section \ref{subsec:proj3} remain relevant.

\subsection{Closing Thoughts}
After analysing the proposed (and not) variations to the project, in particular the third and fifth, we may come to the conclusion that even if it was possible to increase the time tools take to break, it might not be a good idea so long as a Round-Robin approach with relatively low time slices is not implemented by design. We can also conclude that we can prefer stations that behave as close as possible to negative exponential distributed ones.


%%% End document
\end{document}